{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "\n",
    "1. **LoadingService**: 新增 `load_epub`，支持提取 EPUB 文本与图片元数据。\n",
    "2. **ParsingService**: 新增 `extract_tables_from_pdf`，集成 `pdfplumber` 实现精确的表格结构化提取。\n",
    "3. **ChunkingService**: 增强 `chunk_text`，新增对结构化表格数据的专用分块逻辑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend path added: d:\\My Data\\Rag\\rag-project01-framework\\backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\My Data\\Rag\\rag-project01-framework\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPUB Path: d:\\My Data\\Rag\\rag-project01-framework\\asset\\投资第一课 (孟岩) (Z-Library).epub\n",
      "PDF Path: d:\\My Data\\Rag\\rag-project01-framework\\asset\\billionaires_page-1-5.pdf\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display, JSON, Image\n",
    "\n",
    "# 添加 backend 路径\n",
    "current_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "backend_path = os.path.join(project_root, 'backend')\n",
    "\n",
    "if backend_path not in sys.path:\n",
    "    sys.path.append(backend_path)\n",
    "\n",
    "print(f\"Backend path added: {backend_path}\")\n",
    "\n",
    "# 导入服务\n",
    "from services.loading_service import LoadingService\n",
    "from services.parsing_service import ParsingService\n",
    "from services.chunking_service import ChunkingService\n",
    "\n",
    "# 初始化服务\n",
    "loading_service = LoadingService()\n",
    "parsing_service = ParsingService()\n",
    "chunking_service = ChunkingService()\n",
    "\n",
    "# 资源路径\n",
    "asset_dir = os.path.join(project_root, 'asset')\n",
    "epub_path = os.path.join(asset_dir, \"投资第一课 (孟岩) (Z-Library).epub\")\n",
    "pdf_path = os.path.join(asset_dir, \"billionaires_page-1-5.pdf\")\n",
    "\n",
    "print(f\"EPUB Path: {epub_path}\")\n",
    "print(f\"PDF Path: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_epub",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载 EPUB 文件...\n",
      "\n",
      "加载完成！提取文本长度: 169396 字符\n",
      "包含章节/文件数: 18\n",
      "\n",
      "发现图片资源: 171 张\n",
      "前 5 张图片信息:\n",
      "[\n",
      "  {\n",
      "    \"filename\": \"OEBPS/Images/0000_logo-square-727a22ab924433bf624c1e7aa0b05dae.png\",\n",
      "    \"path\": \"OEBPS/Images/0000_logo-square-727a22ab924433bf624c1e7aa0b05dae.png\",\n",
      "    \"type\": \"image\"\n",
      "  },\n",
      "  {\n",
      "    \"filename\": \"OEBPS/Images/0001_01ERETD53FSSZRW8TQC7AGRW10.png\",\n",
      "    \"path\": \"OEBPS/Images/0001_01ERETD53FSSZRW8TQC7AGRW10.png\",\n",
      "    \"type\": \"image\"\n",
      "  },\n",
      "  {\n",
      "    \"filename\": \"OEBPS/Images/0002_01EC9BB814C3KA6T3BCVD2P0AV.jpg\",\n",
      "    \"path\": \"OEBPS/Images/0002_01EC9BB814C3KA6T3BCVD2P0AV.jpg\",\n",
      "    \"type\": \"image\"\n",
      "  },\n",
      "  {\n",
      "    \"filename\": \"OEBPS/Images/0003_badge-employee-3e0ee5bdffa77d712d5cc795c20c2aa4.png\",\n",
      "    \"path\": \"OEBPS/Images/0003_badge-employee-3e0ee5bdffa77d712d5cc795c20c2aa4.png\",\n",
      "    \"type\": \"image\"\n",
      "  },\n",
      "  {\n",
      "    \"filename\": \"OEBPS/Images/0004_01EDT6NYMVM7HVFXZ66M5RN4B5.jpg\",\n",
      "    \"path\": \"OEBPS/Images/0004_01EDT6NYMVM7HVFXZ66M5RN4B5.jpg\",\n",
      "    \"type\": \"image\"\n",
      "  }\n",
      "]\n",
      "\n",
      "--- 文本内容预览 (前 500 字符) ---\n",
      "我是谁？\n",
      "导读 | 这一回，从门外汉到 80 分投资者\n",
      "有知有行 ·\n",
      "2020年12月2日\n",
      "150316\n",
      "965\n",
      "你好，我是孟岩。\n",
      "欢迎你来到《有知有行·投资第一课》。\n",
      "当你打开这篇文章的时候，我其实想先问你，也问我自己一个问题：知识经济时代，有关投资的课程数不胜数，你为什么要花时间来学习又一门课？\n",
      "神经科学家通过研究发现，人脑在接收信息时，会先和自己已有的认知相比较，如果不同，大脑会启动情绪来对抗。\n",
      "选择哪门课程，往小说无非是花一些时间，但往大说，其实是向我们的脑子中植入一些信息。而这些信息很有可能会排斥其它的信息。从这个角度说，选择学什么，听谁讲，其实非常重要。\n",
      "我是谁？\n",
      "因此，我决定先介绍一下自己。\n",
      "我叫孟岩，从 2005 年开始学习投资，2009 年正式开始记录自己的投资业绩，\n",
      "长期投资\n",
      "业绩在年化 20% 左右。\n",
      "我不是科班出身。\n",
      "1997 年，我考入北京航空航天大学计算机科学与工程系，开始了 7 年的学习。这段经历对我很重要，现在回想，它给我留下最大的烙印是我意识到我可以用代码和产品来创造一些这个世界上本来并没有的东西，给别人提供价值，直到现在，这依然是最让我兴奋的事情。\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# 调用 `LoadingService.load_epub`，它会自动解压 EPUB，提取所有 HTML 文本，并识别图片资源。\n",
    "if os.path.exists(epub_path):\n",
    "    print(\"正在加载 EPUB 文件...\")\n",
    "    # 1. 加载 EPUB\n",
    "    epub_text = loading_service.load_epub(epub_path)\n",
    "    \n",
    "    # 2. 展示文本统计\n",
    "    print(f\"\\n加载完成！提取文本长度: {len(epub_text)} 字符\")\n",
    "    print(f\"包含章节/文件数: {len(loading_service.current_page_map)}\")\n",
    "    \n",
    "    # 3. 展示图片元数据\n",
    "    images = getattr(loading_service, 'current_images', [])\n",
    "    print(f\"\\n发现图片资源: {len(images)} 张\")\n",
    "    if images:\n",
    "        print(\"前 5 张图片信息:\")\n",
    "        print(json.dumps(images[:5], indent=2, ensure_ascii=False))\n",
    "        \n",
    "    # 4. 展示部分文本内容\n",
    "    print(\"\\n--- 文本内容预览 (前 500 字符) ---\")\n",
    "    print(epub_text[:500] + \"...\")\n",
    "else:\n",
    "    print(\"EPUB 文件不存在，跳过此步骤。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parse_pdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在解析 PDF 表格...\n",
      "\n",
      "解析完成！共提取 7 个表格\n",
      "\n",
      "--- 表格 1 (Page 1) 预览 ---\n",
      "维度: 15 行 x 1 列\n",
      "前 3 行数据:\n",
      "[\"List of the world's billionaires, ranked in order of net worth\"]\n",
      "[\"The net worth of the world's billionaires increased from\\nless than US$1 trillion in 2000 to over $7 trillion in 2015.\"]\n",
      "['Publication details']\n"
     ]
    }
   ],
   "source": [
    "#调用 `ParsingService.extract_tables_from_pdf`，直接利用 `pdfplumber` 的能力提取表格，而不是将其视为纯文本。\n",
    "if os.path.exists(pdf_path):\n",
    "    print(\"正在解析 PDF 表格...\")\n",
    "    # 1. 提取表格\n",
    "    tables = parsing_service.extract_tables_from_pdf(pdf_path)\n",
    "    \n",
    "    print(f\"\\n解析完成！共提取 {len(tables)} 个表格\")\n",
    "    \n",
    "    if tables:\n",
    "        # 展示第一个表格的结构\n",
    "        first_table = tables[0]\n",
    "        print(f\"\\n--- 表格 1 (Page {first_table['page']}) 预览 ---\")\n",
    "        print(f\"维度: {first_table['metadata']['rows']} 行 x {first_table['metadata']['cols']} 列\")\n",
    "        \n",
    "        # 简单展示前几行数据\n",
    "        print(\"前 3 行数据:\")\n",
    "        for row in first_table['data'][:3]:\n",
    "            print(row)\n",
    "else:\n",
    "    print(\"PDF 文件不存在，跳过此步骤。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chunk_tables",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在对表格数据进行分块...\n",
      "\n",
      "分块完成！生成 7 个 Chunk\n",
      "\n",
      "--- 最终文档 JSON 结构 (预览第一个 Chunk) ---\n",
      "{\n",
      "  \"content\": \"Table Data (Page 1):\\n[[\\\"List of the world's billionaires, ranked in order of net worth\\\"], [\\\"The net worth of the world's billionaires increased from\\\\nless than US$1 trillion in 2000 to over $7 trillion in 2015.\\\"], [\\\"Publication details\\\"], [\\\"Publisher Whale Media Investments\\\\nForbes family\\\"], [\\\"Publication Forbes\\\"], [\\\"First published March 1987[1]\\\"], [\\\"Latest publication April 4, 2023\\\"], [\\\"Current list details (2023)[2]\\\"], [\\\"Wealthiest Bernard Arnault\\\"], [\\\"Net worth (1st) US$211 billion\\\"], [\\\"Number of 2,640 (from 2668)\\\\nbillionaires\\\"], [\\\"Total list net worth US$12.2 trillion (from US$ 12.7\\\\nvalue trillion)\\\"], [\\\"Number of women 337\\\"], [\\\"New members to the 150\\\\nlist\\\"], [\\\"Forbes: The World's Billionaires website (https://www.forb\\\\nes.com/billionaires/)\\\"]]\",\n",
      "  \"metadata\": {\n",
      "    \"chunk_id\": 1,\n",
      "    \"page_number\": 1,\n",
      "    \"page_range\": \"1\",\n",
      "    \"type\": \"table\",\n",
      "    \"table_index\": 0,\n",
      "    \"rows\": 15,\n",
      "    \"cols\": 1\n",
      "  }\n",
      "}\n",
      "\n",
      "完整结果已保存至: homework_5_result.json\n"
     ]
    }
   ],
   "source": [
    "#调用 `ChunkingService.chunk_text`，它现在能够智能识别传入的是“结构化表格数据”，并应用专门的 `by_table` 分块策略，生成语义完整的 Chunk。\n",
    "if os.path.exists(pdf_path) and tables:\n",
    "    print(\"正在对表格数据进行分块...\")\n",
    "    \n",
    "    # 1. 构造 Metadata\n",
    "    doc_metadata = {\n",
    "        \"filename\": os.path.basename(pdf_path),\n",
    "        \"loading_method\": \"pdfplumber\"\n",
    "    }\n",
    "    \n",
    "    # 2. 执行分块 (自动触发 _chunk_tables 逻辑)\n",
    "    chunked_doc = chunking_service.chunk_text(\n",
    "        text=\"\", # 对于表格分块，text 参数被忽略\n",
    "        method=\"by_table\", # 这个参数在内部逻辑中其实被 page_map 的类型覆盖了，但为了语义清晰我们传它\n",
    "        metadata=doc_metadata,\n",
    "        page_map=tables # 传入结构化的表格数据\n",
    "    )\n",
    "    \n",
    "    # 3. 展示结果 JSON 结构\n",
    "    print(f\"\\n分块完成！生成 {chunked_doc['total_chunks']} 个 Chunk\")\n",
    "    \n",
    "    print(\"\\n--- 最终文档 JSON 结构 (预览第一个 Chunk) ---\")\n",
    "    print(json.dumps(chunked_doc['chunks'][0], indent=2, ensure_ascii=False))\n",
    "    \n",
    "    # 4. 保存为 JSON 文件 (模拟保存)\n",
    "    output_file = \"homework_5_result.json\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(chunked_doc, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\n完整结果已保存至: {output_file}\")\n",
    "else:\n",
    "    print(\"跳过分块步骤。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

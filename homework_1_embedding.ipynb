{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09e416ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend path added: d:\\My Data\\Rag\\rag-project01-framework\\backend\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 添加 backend 路径\n",
    "current_dir = os.getcwd()\n",
    "if 'notebooks' in current_dir:\n",
    "    backend_path = os.path.abspath(os.path.join(current_dir, '..', 'backend'))\n",
    "    env_path = os.path.abspath(os.path.join(current_dir, '..', 'backend', '.env'))\n",
    "else:\n",
    "    backend_path = os.path.abspath(os.path.join(current_dir, 'backend'))\n",
    "    env_path = os.path.abspath(os.path.join(current_dir, 'backend', '.env'))\n",
    "\n",
    "if backend_path not in sys.path:\n",
    "    sys.path.append(backend_path)\n",
    "\n",
    "load_dotenv(env_path)\n",
    "print(f\"Backend path added: {backend_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f028600a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmbeddingService initialized.\n"
     ]
    }
   ],
   "source": [
    "from services.embedding_service import EmbeddingService, EmbeddingConfig, EmbeddingProvider\n",
    "\n",
    "# 初始化 Embedding 服务\n",
    "embedding_service = EmbeddingService()\n",
    "print(\"EmbeddingService initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "883b0a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama service is running.\n",
      "Generating embedding using OLLAMA: nomic-embed-text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\My Data\\Rag\\rag-project01-framework\\backend\\services\\embedding_service.py:429: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Vector dimension: 768\n",
      "First 10 dimensions: [-0.9311626553535461, 0.4479086101055145, -3.781853437423706, 0.15555579960346222, 2.1204097270965576, 0.4446313679218292, -0.18387795984745026, -0.23778729140758514, 0.5790306925773621, -0.002641927218064666]\n"
     ]
    }
   ],
   "source": [
    "test_text = \"DeepSeek is an advanced AI model provider.\"\n",
    "\n",
    "# 使用 Ollama 本地模型\n",
    "# 请确保你已经安装了 Ollama 并运行了: ollama pull nomic-embed-text\n",
    "local_model_name = \"nomic-embed-text\"\n",
    "\n",
    "try:\n",
    "    # 检查 Ollama 服务状态 (可选)\n",
    "    import requests\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:11434\")\n",
    "        if response.status_code == 200:\n",
    "            print(\"Ollama service is running.\")\n",
    "        else:\n",
    "            print(f\"WARNING: Ollama service returned status {response.status_code}\")\n",
    "    except Exception:\n",
    "        print(\"WARNING: Could not connect to Ollama at http://localhost:11434. Is it running?\")\n",
    "\n",
    "    print(f\"Generating embedding using OLLAMA: {local_model_name}...\")\n",
    "    embedding_vector = embedding_service.create_single_embedding(\n",
    "        text=test_text,\n",
    "        provider=EmbeddingProvider.OLLAMA,\n",
    "        model=local_model_name\n",
    "    )\n",
    "    \n",
    "    print(f\"Success! Vector dimension: {len(embedding_vector)}\")\n",
    "    print(f\"First 10 dimensions: {embedding_vector[:10]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"请确保你安装了 Ollama 并运行了 `ollama pull nomic-embed-text`\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
